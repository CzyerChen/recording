- Java内存模型是学习Java的非常重要的一个知识点，下面就一起来学一学
- 前提先了解一下JVM内存模型和Java内存模型的关系
    - JVM内存模式指的是JVM的内存分区；而Java内存模式是一种虚拟机规范
    - Java虚拟机规范中定义了Java内存模型（Java Memory Model，JMM），用于屏蔽掉各种硬件和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的并发效果
    - JMM规范了Java虚拟机与计算机内存是如何协同工作的：规定了一个线程如何和何时可以看到由其他线程修改过后的共享变量的值，以及在必须时如何同步的访问共享变量
- 学习资源来自互联网和并发编程网（ 转载自并发编程网 – ifeve.com 深入理解Java内存模型 ）
    
#### 1. 共享内存和消息传递
- 并发编程的两个关键问题：线程之间如何通信及线程之间如何同步
- 通信是指线程之间以何种机制来交换信息
- 命令式编程中，线程之间的通信机制有两种：共享内存和消息传递
- 同步是指程序用于控制不同线程之间操作发生相对顺序的机制
- 在共享内存并发模型里，同步是显式进行的。程序员必须显式指定某个方法或某段代码需要在线程之间互斥执行
- 在消息传递的并发模型里，由于消息的发送必须在消息的接收之前，因此同步是隐式进行的。
- Java的并发采用的是共享内存模型，Java线程之间的通信总是隐式进行，整个通信过程对程序员完全透明

#### 2. 抽象描述JMM
- java 实例、静态资源都在堆上，是共享内存，局部变量是属于线程的，是私有变量不共享，不存在内存可见问题
- Java线程之间的通信由Java内存模型（本文简称为JMM）控制，JMM决定一个线程对共享变量的写入何时对另一个线程可见

- 线程之间的共享变量存储在主内存（main memory）中，每个线程都有一个私有的本地内存（local memory），本地内存中存储了该线程以读/写共享变量的副本
- 本地内存是JMM的一个抽象概念，并不真实存在。它涵盖了缓存，写缓冲区，寄存器以及其他的硬件和编译器优化
```text

      (Thread A )                       (Thread B)
           |                                |   
      |-----------|                    |-----------|
      | 本地内存A  |                    | 本地内存B  |
      | （副本）   |                    |  （副本）  |
      |-----------|                    |-----------|
            |                                 |
            |----------JMM控制----------------|
            |                                 |
    |---------------------------------------------------|
    |                      主内存                        |
    |      （共享变量A）     （共享变量B）   （共享变量C）  |
    |---------------------------------------------------|
```
- 如果线程A要和线程B交互，并对共享变量B进行操作，那么两个线程都必须保证获取了主内存中的最新变量版本到本地内存，才能进行交互

#### 3.重排序的概念
- 执行程序时为了提高性能，编译器和处理器常常会对指令做重排序
- 重排序分为三种：编译器重排、指令级并行重排、内存系统的重排
   - 1.编译器重排：编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序
   - 2.指令重排:指令级并行技术（Instruction-Level Parallelism， ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序
   - 3.内存系统重排:由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行
   - 4.1属于编译器重排序，2和3属于处理器重排序
- JMM的编译器重排序规则会禁止特定类型的编译器重排序
- 处理器重排序，JMM的处理器重排序规则会要求java编译器在生成指令序列时，插入特定类型的内存屏障,通过内存屏障指令来禁止特定类型的处理器重排序
- JMM属于语言级的内存模型，它确保在不同的编译器和不同的处理器平台之上，通过禁止特定类型的编译器重排序和处理器重排序，为程序员提供一致的内存可见性保证

#### 4.处理器重排序与内存屏障指令
- 在java的学习当中，也有听过内存屏障指令，这边具体介绍一下
- 处理器使用写缓冲区来临时保存向内存写入的数据，可以保存临时数据，批量操作写入缓冲区，然后一次性合并缓冲区到同意内存地址的多次写，这样的优点就是可以减少对总线内存的占用，但是正式因为由本地缓冲的概念，就造成了一些内存可见的问题
- 不同处理器会指令重排序的支持不同，在读写的操作的指令重排序，大多数的操作系统都是支持的
- 出于以上情况，因而会出现，a=b=0,thread1: a=1,x=b;thread2:b=2,y=a,最终结果是x=y=0，而不是我们所想的那样
- 以上，虽然我们认为先进行本地a,b的重新赋值，然后刷新到主存中,然后在进行本地赋值给x,y，但是操作系统会对读写的指令重排
- 以上，先将a=b=0读取到本地，然后进行本地操作，然后将本地值刷新到主存，因而出现x=y=0
- 常见的处理器都允许Store-Load重排序；常见的处理器都不允许对存在数据依赖的操作做重排序。sparc-TSO和x86拥有相对较强的处理器内存模型，它们仅允许对写-读操作做重排序（因为它们都使用了写缓冲区）
- 为了保证内存可见性，java编译器在生成指令序列的适当位置会插入内存屏障指令来禁止特定类型的处理器重排序

#### 内存屏障的分类：
- LoadLoad Barriers ： 确保Load1数据的装载之后，之前于Load2及所有后续装载指令的装载
```text
Load1; 
LoadLoad; 
Load2
```
- StoreStore Barriers：确保Store1数据对其他处理器可见（刷新到内存）之后，之前于Store2及所有后续存储指令的存储
```text
Store1; 
StoreStore; 
Store2
```
- LoadStore Barriers:确保Load1数据装载之后，之前于Store2及所有后续的存储指令刷新到内存
```text
Load1; 
LoadStore; 
Store2
```
- StoreLoad Barriers:确保Store1数据对其他处理器变得可见（指刷新到内存），之前于Load2及所有后续装载指令的装载
- StoreLoad Barriers会使该屏障之前的所有内存访问指令（存储和装载指令）完成之后，才执行该屏障之后的内存访问指令
```text
Store1; 
StoreLoad; 
Load2
```
- StoreLoad Barriers是一个“全能型”的屏障，它同时具有其他三个屏障的效果
- 现代的多处理器大都支持该屏障,执行该屏障开销会很昂贵，因为当前处理器通常要把写缓冲区中的数据全部刷新到内存中

#### 5. happens-before
- 在JMM中，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须要存在happens-before关系
- happens-before的规则：
    - 程序顺序规则：一个线程中的每个操作，happens- before 于该线程中的任意后续操作
    - 监视器锁规则：对一个监视器锁的解锁，happens- before 于随后对这个监视器锁的加锁
    - volatile变量规则：对一个volatile域的写，happens- before 于任意后续对这个volatile域的读
    - 传递性：如果A happens- before B，且B happens- before C，那么A happens- before C
- 一个happens-before规则通常对应于多个编译器和处理器重排序规则
- 封装了复杂的重排序规则，是程序员能够直接利用内存可见的特点


### 二、重排序

### 三、顺序一致性
### 四、volatile
### 五、锁
### 六、final
### 七、总结